{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301bf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cab31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a05f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f967ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e25a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f88efc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a5f39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3b16eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data structures that will be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09ac1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4717806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca3c2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "bookUsers = defaultdict(set)\n",
    "userBooks = defaultdict(set)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "    bookUsers[b].add(u)\n",
    "    userBooks[u].add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93959f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Read prediction                                #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abb17ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from baseline code\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalRead/2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80f40789",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c9eea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy on valid: 0.71125\n"
     ]
    }
   ],
   "source": [
    "negative_samples = []\n",
    "for user, book, _ in ratingsValid:\n",
    "    while True:\n",
    "        negative_book = random.choice(list(bookCount.keys()))\n",
    "        if all(b != negative_book for b, _ in ratingsPerUser[user]):\n",
    "            negative_samples.append((user, negative_book, 0))  # 0 for negative sample\n",
    "            break\n",
    "\n",
    "validation_with_negatives = [(u, b, 1) for u, b, _ in ratingsValid] + negative_samples\n",
    "\n",
    "correct_predictions = 0\n",
    "for user, book, label in validation_with_negatives:\n",
    "    prediction = 1 if book in return1 else 0\n",
    "    if prediction == label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "acc1 = correct_predictions / len(validation_with_negatives)\n",
    "print(f\"model accuracy on valid: {acc1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8af7b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6839df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50491907",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87e03b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.7\n",
      "Best accuracy: 0.7526\n"
     ]
    }
   ],
   "source": [
    "threshold = None\n",
    "acc2 = 0\n",
    "\n",
    "for fraction in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    curr_threshold = totalRead * fraction\n",
    "\n",
    "    popular_books = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        popular_books.add(i)\n",
    "        if count > curr_threshold:\n",
    "            break\n",
    "\n",
    "    correct_predictions = 0\n",
    "    for user, book, label in validation_with_negatives:\n",
    "        prediction = 1 if book in popular_books else 0\n",
    "        if prediction == label:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    curr_acc = correct_predictions / len(validation_with_negatives)\n",
    "    \n",
    "    if curr_acc > acc2:\n",
    "        acc2 = curr_acc\n",
    "        threshold = fraction\n",
    "\n",
    "print(f\"Best threshold: {threshold}\")\n",
    "print(f\"Best accuracy: {acc2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "263c16a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = [threshold, acc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcb6b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q2'][0])\n",
    "assertFloat(answers['Q2'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b753559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04a6f2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002 0.6986\n",
      "0.0022 0.70045\n",
      "0.0024 0.70315\n",
      "0.0026 0.70365\n",
      "0.0028 0.70365\n",
      "0.003 0.70355\n",
      "0.0032 0.70205\n",
      "0.0034 0.70135\n",
      "0.0036 0.70215\n",
      "0.0038 0.7019\n",
      "Best Jaccard similarity threshold: 0.0026\n",
      "Accuracy with best Jaccard threshold: 0.70365\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(book1, book2):\n",
    "    users1 = bookUsers.get(book1, set())\n",
    "    users2 = bookUsers.get(book2, set())\n",
    "    if not users1 or not users2:\n",
    "        return 0\n",
    "    intersection = len(users1.intersection(users2))\n",
    "    union = len(users1.union(users2))\n",
    "    return intersection / union\n",
    "\n",
    "best_threshold = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for threshold in range(20, 40, 2):\n",
    "    threshold = threshold / 10000\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for user, book, label in validation_with_negatives:\n",
    "        # find max jaccard sim between books\n",
    "        max_jaccard_sim = max([jaccard_similarity(book, b_read) for b_read in userBooks[user]], default=0)\n",
    "        \n",
    "        # predict as read if above threshold\n",
    "        prediction = 1 if max_jaccard_sim > threshold else 0\n",
    "\n",
    "        if prediction == label:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / len(validation_with_negatives)\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_threshold = threshold\n",
    "\n",
    "    print(threshold, accuracy)\n",
    "\n",
    "\n",
    "print(f\"Best Jaccard similarity threshold: {best_threshold}\")\n",
    "print(f\"Accuracy with best Jaccard threshold: {best_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a6b1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc3 = best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bd1adb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity fraction: 0.68, Jaccard threshold: 0.0, Accuracy: 0.69775\n",
      "Popularity fraction: 0.68, Jaccard threshold: 0.01, Accuracy: 0.74925\n",
      "Popularity fraction: 0.68, Jaccard threshold: 0.02, Accuracy: 0.7515\n",
      "Popularity fraction: 0.68, Jaccard threshold: 0.03, Accuracy: 0.75205\n",
      "Popularity fraction: 0.68, Jaccard threshold: 0.04, Accuracy: 0.75165\n",
      "Popularity fraction: 0.68, Jaccard threshold: 0.05, Accuracy: 0.752\n",
      "Popularity fraction: 0.68, Jaccard threshold: 0.06, Accuracy: 0.7518\n",
      "Popularity fraction: 0.68, Jaccard threshold: 0.07, Accuracy: 0.75185\n",
      "Popularity fraction: 0.68, Jaccard threshold: 0.08, Accuracy: 0.75175\n",
      "Popularity fraction: 0.68, Jaccard threshold: 0.09, Accuracy: 0.7518\n",
      "Popularity fraction: 0.7, Jaccard threshold: 0.0, Accuracy: 0.69735\n",
      "Popularity fraction: 0.7, Jaccard threshold: 0.01, Accuracy: 0.74895\n",
      "Popularity fraction: 0.7, Jaccard threshold: 0.02, Accuracy: 0.75245\n",
      "Popularity fraction: 0.7, Jaccard threshold: 0.03, Accuracy: 0.75295\n",
      "Popularity fraction: 0.7, Jaccard threshold: 0.04, Accuracy: 0.75255\n",
      "Popularity fraction: 0.7, Jaccard threshold: 0.05, Accuracy: 0.75295\n",
      "Popularity fraction: 0.7, Jaccard threshold: 0.06, Accuracy: 0.75275\n",
      "Popularity fraction: 0.7, Jaccard threshold: 0.07, Accuracy: 0.7528\n",
      "Popularity fraction: 0.7, Jaccard threshold: 0.08, Accuracy: 0.7527\n",
      "Popularity fraction: 0.7, Jaccard threshold: 0.09, Accuracy: 0.75275\n",
      "Popularity fraction: 0.72, Jaccard threshold: 0.0, Accuracy: 0.69675\n",
      "Popularity fraction: 0.72, Jaccard threshold: 0.01, Accuracy: 0.7483\n",
      "Popularity fraction: 0.72, Jaccard threshold: 0.02, Accuracy: 0.75295\n",
      "Popularity fraction: 0.72, Jaccard threshold: 0.03, Accuracy: 0.7537\n",
      "Popularity fraction: 0.72, Jaccard threshold: 0.04, Accuracy: 0.75335\n",
      "Popularity fraction: 0.72, Jaccard threshold: 0.05, Accuracy: 0.75375\n",
      "Popularity fraction: 0.72, Jaccard threshold: 0.06, Accuracy: 0.75355\n",
      "Popularity fraction: 0.72, Jaccard threshold: 0.07, Accuracy: 0.7536\n",
      "Popularity fraction: 0.72, Jaccard threshold: 0.08, Accuracy: 0.75345\n",
      "Popularity fraction: 0.72, Jaccard threshold: 0.09, Accuracy: 0.7535\n",
      "Popularity fraction: 0.74, Jaccard threshold: 0.0, Accuracy: 0.69605\n",
      "Popularity fraction: 0.74, Jaccard threshold: 0.01, Accuracy: 0.7471\n",
      "Popularity fraction: 0.74, Jaccard threshold: 0.02, Accuracy: 0.7523\n",
      "Popularity fraction: 0.74, Jaccard threshold: 0.03, Accuracy: 0.75325\n",
      "Popularity fraction: 0.74, Jaccard threshold: 0.04, Accuracy: 0.753\n",
      "Popularity fraction: 0.74, Jaccard threshold: 0.05, Accuracy: 0.7534\n",
      "Popularity fraction: 0.74, Jaccard threshold: 0.06, Accuracy: 0.7533\n",
      "Popularity fraction: 0.74, Jaccard threshold: 0.07, Accuracy: 0.7534\n",
      "Popularity fraction: 0.74, Jaccard threshold: 0.08, Accuracy: 0.75325\n",
      "Popularity fraction: 0.74, Jaccard threshold: 0.09, Accuracy: 0.7533\n",
      "Best popularity fraction: 0.72\n",
      "Best Jaccard similarity threshold: 0.05\n",
      "Combined accuracy with best thresholds: 0.75375\n"
     ]
    }
   ],
   "source": [
    "# Popularity-based threshold tuning\n",
    "pop_threshold = None\n",
    "pop_accuracy = 0\n",
    "\n",
    "for fraction in [0.68, 0.7, 0.72, 0.74]:\n",
    "    curr_pop_threshold = totalRead * fraction\n",
    "\n",
    "    # Select popular books based on threshold\n",
    "    popular_books = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        popular_books.add(i)\n",
    "        if count > curr_pop_threshold:\n",
    "            break\n",
    "\n",
    "    # Jaccard-based threshold tuning within popular book criteria\n",
    "    for jaccard_threshold in range(0, 10):\n",
    "        jaccard_threshold = jaccard_threshold / 100\n",
    "        correct_predictions = 0\n",
    "\n",
    "        for user, book, label in validation_with_negatives:\n",
    "            # Check popularity criterion first\n",
    "            if book in popular_books:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                max_jaccard_sim = max([jaccard_similarity(book, b_read) for b_read in userBooks[user]], default=0)\n",
    "                prediction = 1 if max_jaccard_sim > jaccard_threshold else 0\n",
    "            \n",
    "            if prediction == label:\n",
    "                correct_predictions += 1\n",
    "\n",
    "        accuracy = correct_predictions / len(validation_with_negatives)\n",
    "\n",
    "        # Track best combination of popularity and Jaccard thresholds\n",
    "        if accuracy > pop_accuracy:\n",
    "            pop_accuracy = accuracy\n",
    "            pop_threshold = (fraction, jaccard_threshold)\n",
    "\n",
    "        print(f\"Popularity fraction: {fraction}, Jaccard threshold: {jaccard_threshold}, Accuracy: {accuracy}\")\n",
    "\n",
    "print(f\"Best popularity fraction: {pop_threshold[0]}\")\n",
    "print(f\"Best Jaccard similarity threshold: {pop_threshold[1]}\")\n",
    "print(f\"Combined accuracy with best thresholds: {pop_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0c29cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc4 = pop_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83ab0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = acc3\n",
    "answers['Q4'] = acc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27d6d011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.70365, 0.75375)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc3, acc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbdd0c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q3'])\n",
    "assertFloat(answers['Q4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e68cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Read.csv\", 'w')\n",
    "\n",
    "curr_pop_threshold = totalRead * 0.72\n",
    "jaccard_threshold = 0.05\n",
    "\n",
    "# Select popular books based on threshold\n",
    "popular_books = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    popular_books.add(i)\n",
    "    if count > curr_pop_threshold:\n",
    "        break\n",
    "\n",
    "for l in open(\"pairs_Read.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',')\n",
    "\n",
    "    if b in popular_books:\n",
    "        prediction = 1\n",
    "    else:\n",
    "        max_jaccard_sim = max([jaccard_similarity(b, b_read) for b_read in userBooks[u]], default=0)\n",
    "        prediction = 1 if max_jaccard_sim > jaccard_threshold else 0\n",
    "    \n",
    "    predictions.write(u + ',' + b + ',' + str(prediction) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "297b5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5'] = \"I confirm that I have uploaded an assignment submission to gradescope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3cb95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(answers['Q5']) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcf70975",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Rating prediction                              #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95b960a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56d456d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d81ea89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasOnlyModel:\n",
    "    def __init__(self, lamb, convergence_threshold=1e-4):\n",
    "        self.alpha = 0.0\n",
    "        self.betaU = defaultdict(float)\n",
    "        self.betaI = defaultdict(float)\n",
    "        self.lamb = lamb\n",
    "        self.convergence_threshold = convergence_threshold\n",
    "\n",
    "    def fit(self, train_data, num_epochs=50):\n",
    "        ratings = [d[2] for d in train_data]\n",
    "        self.alpha = np.mean(ratings)\n",
    "\n",
    "        previous_mse = float('inf')\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            alpha_grad = 0.0\n",
    "            betaU_grad = defaultdict(float)\n",
    "            betaI_grad = defaultdict(float)\n",
    "\n",
    "            for user, item, rating in train_data:\n",
    "                pred = self.predict(user, item)\n",
    "                error = rating - pred\n",
    "\n",
    "                alpha_grad += -2 * error\n",
    "                betaU_grad[user] += -2 * error\n",
    "                betaI_grad[item] += -2 * error\n",
    "\n",
    "            for user in betaU_grad:\n",
    "                betaU_grad[user] += 2 * self.lamb * self.betaU[user]\n",
    "            for item in betaI_grad:\n",
    "                betaI_grad[item] += 2 * self.lamb * self.betaI[item]\n",
    "\n",
    "            self.alpha -= alpha_grad / len(train_data)\n",
    "            for user in betaU_grad:\n",
    "                self.betaU[user] -= betaU_grad[user] / len(train_data)\n",
    "            for item in betaI_grad:\n",
    "                self.betaI[item] -= betaI_grad[item] / len(train_data)\n",
    "\n",
    "            mse_train = self.calculate_mse(train_data)\n",
    "            print(f\"Epoch {epoch + 1}, Training MSE: {mse_train}\")\n",
    "\n",
    "            if abs(previous_mse - mse_train) < self.convergence_threshold:\n",
    "                print(\"Convergence achieved.\")\n",
    "                break\n",
    "\n",
    "            previous_mse = mse_train\n",
    "\n",
    "    def predict(self, user, item):\n",
    "        return self.alpha + self.betaU[user] + self.betaI[item]\n",
    "\n",
    "    def calculate_sse(self, data):\n",
    "        sse = 0.0\n",
    "        for user, item, rating in data:\n",
    "            pred = self.predict(user, item)\n",
    "            sse += (rating - pred) ** 2\n",
    "\n",
    "        sse += self.lamb * (sum(b ** 2 for b in self.betaU.values()) + sum(b ** 2 for b in self.betaI.values()))\n",
    "        return sse\n",
    "\n",
    "    def calculate_mse(self, data):\n",
    "        sse = self.calculate_sse(data)\n",
    "        return sse / len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "01d1c447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training MSE: 1.7385038717138568\n",
      "Epoch 2, Training MSE: 1.7379082555901695\n",
      "Epoch 3, Training MSE: 1.7373174540127907\n",
      "Epoch 4, Training MSE: 1.7367314026164713\n",
      "Epoch 5, Training MSE: 1.7361500380262862\n",
      "Epoch 6, Training MSE: 1.7355732978415486\n",
      "Epoch 7, Training MSE: 1.7350011206193425\n",
      "Epoch 8, Training MSE: 1.734433445858994\n",
      "Epoch 9, Training MSE: 1.733870213986438\n",
      "Epoch 10, Training MSE: 1.7333113663391335\n",
      "Epoch 11, Training MSE: 1.7327568451505382\n",
      "Epoch 12, Training MSE: 1.7322065935360416\n",
      "Epoch 13, Training MSE: 1.7316605554780022\n",
      "Epoch 14, Training MSE: 1.7311186758117287\n",
      "Epoch 15, Training MSE: 1.7305809002112948\n",
      "Epoch 16, Training MSE: 1.7300471751759166\n",
      "Epoch 17, Training MSE: 1.7295174480164321\n",
      "Epoch 18, Training MSE: 1.7289916668420284\n",
      "Epoch 19, Training MSE: 1.7284697805469877\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m BiasOnlyModel(lamb\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratingsTrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m validMSE \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcalculate_mse(ratingsValid)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation MSE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, validMSE)\n",
      "Cell \u001b[0;32mIn[93], line 21\u001b[0m, in \u001b[0;36mBiasOnlyModel.fit\u001b[0;34m(self, train_data, num_epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m betaI_grad \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user, item, rating \u001b[38;5;129;01min\u001b[39;00m train_data:\n\u001b[0;32m---> 21\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     error \u001b[38;5;241m=\u001b[39m rating \u001b[38;5;241m-\u001b[39m pred\n\u001b[1;32m     24\u001b[0m     alpha_grad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m error\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = BiasOnlyModel(lamb=1)\n",
    "\n",
    "model.fit(ratingsTrain, num_epochs=200)\n",
    "\n",
    "validMSE = model.calculate_mse(ratingsValid)\n",
    "print(\"Validation MSE:\", validMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ced46259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect unique user and item IDs from both training and validation data\n",
    "user_ids = set()\n",
    "item_ids = set()\n",
    "for u, b, r in ratingsTrain + ratingsValid:\n",
    "    user_ids.add(u)\n",
    "    item_ids.add(b)\n",
    "\n",
    "# Create mappings from IDs to indices\n",
    "user2index = {user_id: idx for idx, user_id in enumerate(sorted(user_ids))}\n",
    "item2index = {item_id: idx for idx, item_id in enumerate(sorted(item_ids))}\n",
    "num_users = len(user2index)\n",
    "num_items = len(item2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f678091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, user2index, item2index):\n",
    "    user_indices = torch.tensor([user2index[u] for u, _, _ in data], dtype=torch.long)\n",
    "    item_indices = torch.tensor([item2index[b] for _, b, _ in data], dtype=torch.long)\n",
    "    ratings = torch.tensor([float(r) for _, _, r in data], dtype=torch.float)\n",
    "    return user_indices, item_indices, ratings\n",
    "\n",
    "train_users, train_items, train_ratings = prepare_data(ratingsTrain, user2index, item2index)\n",
    "val_users, val_items, val_ratings = prepare_data(ratingsValid, user2index, item2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "577df8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = torch.nn.Parameter(torch.tensor(0.0))\n",
    "beta_user = torch.nn.Parameter(torch.zeros(num_users))\n",
    "beta_item = torch.nn.Parameter(torch.zeros(num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c45e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.LBFGS([alpha, beta_user, beta_item])\n",
    "lambda_reg = 1.0  # Regularization parameter\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    predictions = alpha + beta_user[train_users] + beta_item[train_items]\n",
    "    errors = train_ratings - predictions\n",
    "    loss = (errors ** 2).sum()\n",
    "    reg_term = lambda_reg * (beta_user ** 2).sum() + lambda_reg * (beta_item ** 2).sum()\n",
    "    total_loss = loss + reg_term\n",
    "    total_loss.backward()\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "add20fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 1.4422765970230103\n"
     ]
    }
   ],
   "source": [
    "optimizer.step(closure)\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_predictions = alpha + beta_user[val_users] + beta_item[val_items]\n",
    "    val_errors = val_ratings - val_predictions\n",
    "    val_mse = (val_errors ** 2).mean()\n",
    "    print(\"Validation MSE:\", val_mse.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "422ab930",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6'] = float(val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "226252d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4422765970230103"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5509bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3a8594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User with largest beta_u: User ID = u79275096, beta_u = 1.7030433416366577\n",
      "User with smallest beta_u: User ID = u88024921, beta_u = -3.7170488834381104\n"
     ]
    }
   ],
   "source": [
    "# Access the beta_user tensor\n",
    "beta_user_values = beta_user.detach()\n",
    "\n",
    "# Find the indices of the largest and smallest beta_u\n",
    "idx_max = torch.argmax(beta_user_values).item()\n",
    "idx_min = torch.argmin(beta_user_values).item()\n",
    "\n",
    "# Create an inverse mapping from index to user ID\n",
    "index2user = {idx: user_id for user_id, idx in user2index.items()}\n",
    "\n",
    "# Get the user IDs\n",
    "user_id_max = index2user[idx_max]\n",
    "user_id_min = index2user[idx_min]\n",
    "\n",
    "# Get the beta_u values\n",
    "beta_max = beta_user_values[idx_max].item()\n",
    "beta_min = beta_user_values[idx_min].item()\n",
    "\n",
    "# Report the results\n",
    "print(f\"User with largest beta_u: User ID = {user_id_max}, beta_u = {beta_max}\")\n",
    "print(f\"User with smallest beta_u: User ID = {user_id_min}, beta_u = {beta_min}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9826cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7\n",
    "maxUser = user_id_max\n",
    "maxBeta = beta_max\n",
    "minUser = user_id_min\n",
    "minBeta = beta_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c61b675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q7'] = [maxUser, minUser, maxBeta, minBeta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a68e3c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u79275096', 'u88024921', 1.7030433416366577, -3.7170488834381104]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7aca2bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [type(x) for x in answers['Q7']] == [str, str, float, float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a416949",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae54cf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing lambda = 0.001\n",
      "Validation MSE: 1.475295066833496\n",
      "\n",
      "Testing lambda = 0.01\n",
      "Validation MSE: 1.4748600721359253\n",
      "\n",
      "Testing lambda = 0.1\n",
      "Validation MSE: 1.4707632064819336\n",
      "\n",
      "Testing lambda = 1\n",
      "Validation MSE: 1.439719557762146\n",
      "\n",
      "Testing lambda = 5\n",
      "Validation MSE: 1.4115872383117676\n",
      "\n",
      "Testing lambda = 10\n",
      "Validation MSE: 1.433851957321167\n",
      "\n",
      "Testing lambda = 20\n",
      "Validation MSE: 1.4809942245483398\n",
      "\n",
      "Testing lambda = 50\n",
      "Validation MSE: 1.5545440912246704\n",
      "\n",
      "Testing lambda = 100\n",
      "Validation MSE: 1.6021572351455688\n",
      "\n",
      "Lambda vs Validation MSE:\n",
      "Lambda: 0.001, Validation MSE: 1.475295066833496\n",
      "Lambda: 0.01, Validation MSE: 1.4748600721359253\n",
      "Lambda: 0.1, Validation MSE: 1.4707632064819336\n",
      "Lambda: 1, Validation MSE: 1.439719557762146\n",
      "Lambda: 5, Validation MSE: 1.4115872383117676\n",
      "Lambda: 10, Validation MSE: 1.433851957321167\n",
      "Lambda: 20, Validation MSE: 1.4809942245483398\n",
      "Lambda: 50, Validation MSE: 1.5545440912246704\n",
      "Lambda: 100, Validation MSE: 1.6021572351455688\n"
     ]
    }
   ],
   "source": [
    "lambda_values = [0.001, 0.01, 0.1, 1, 5, 10, 20, 50, 100]\n",
    "results = []\n",
    "\n",
    "for lambda_reg in lambda_values:\n",
    "    print(f\"\\nTesting lambda = {lambda_reg}\")\n",
    "    # Initialize parameters\n",
    "    alpha = torch.nn.Parameter(torch.tensor(0.0))\n",
    "    beta_user = torch.nn.Parameter(torch.zeros(num_users))\n",
    "    beta_item = torch.nn.Parameter(torch.zeros(num_items))\n",
    "    \n",
    "    # Set up optimizer\n",
    "    optimizer = torch.optim.LBFGS([alpha, beta_user, beta_item])\n",
    "    \n",
    "    # Define objective function\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        predictions = alpha + beta_user[train_users] + beta_item[train_items]\n",
    "        errors = train_ratings - predictions\n",
    "        loss = (errors ** 2).sum()\n",
    "        # Regularization term (excluding alpha)\n",
    "        reg_term = lambda_reg * ((beta_user ** 2).sum() + (beta_item ** 2).sum())\n",
    "        total_loss = loss + reg_term\n",
    "        total_loss.backward()\n",
    "        return total_loss\n",
    "    \n",
    "    # Train the model\n",
    "    optimizer.step(closure)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    with torch.no_grad():\n",
    "        val_predictions = alpha + beta_user[val_users] + beta_item[val_items]\n",
    "        val_errors = val_ratings - val_predictions\n",
    "        val_mse = (val_errors ** 2).mean().item()\n",
    "        print(f\"Validation MSE: {val_mse}\")\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'lambda': lambda_reg,\n",
    "        'val_mse': val_mse,\n",
    "        'alpha': alpha.item(),\n",
    "        'beta_user': beta_user.detach().clone(),\n",
    "        'beta_item': beta_item.detach().clone()\n",
    "    })\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nLambda vs Validation MSE:\")\n",
    "for res in results:\n",
    "    print(f\"Lambda: {res['lambda']}, Validation MSE: {res['val_mse']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e9f7d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb = 5\n",
    "validMSE = 1.4115872383117676"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f1880fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q8'] = (lamb, validMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "56b09160",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q8'][0])\n",
    "assertFloat(answers['Q8'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2133516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set lambda to 5\n",
    "lambda_reg = 5.0\n",
    "\n",
    "# Initialize parameters\n",
    "alpha = torch.nn.Parameter(torch.tensor(0.0))\n",
    "beta_user = torch.nn.Parameter(torch.zeros(num_users))\n",
    "beta_item = torch.nn.Parameter(torch.zeros(num_items))\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = torch.optim.LBFGS([alpha, beta_user, beta_item])\n",
    "\n",
    "# Define objective function with lambda = 5\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    predictions = alpha + beta_user[train_users] + beta_item[train_items]\n",
    "    errors = train_ratings - predictions\n",
    "    loss = (errors ** 2).sum()\n",
    "    # Regularization term (excluding alpha)\n",
    "    reg_term = lambda_reg * ((beta_user ** 2).sum() + (beta_item ** 2).sum())\n",
    "    total_loss = loss + reg_term\n",
    "    total_loss.backward()\n",
    "    return total_loss\n",
    "\n",
    "# Train the model\n",
    "optimizer.step(closure)\n",
    "\n",
    "# After training, detach parameters from computation graph\n",
    "alpha_value = alpha.detach().item()\n",
    "beta_user_values = beta_user.detach()\n",
    "beta_item_values = beta_item.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b9bd53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rating.csv\", 'w')\n",
    "\n",
    "# Open the pairs file and read line by line\n",
    "with open(\"assignment1/pairs_Rating.csv\", 'r') as pairs_file:\n",
    "    for line in pairs_file:\n",
    "        if line.startswith(\"userID\"):  # Header\n",
    "            predictions.write(line)\n",
    "            continue\n",
    "        userID, itemID = line.strip().split(',')\n",
    "\n",
    "        # Handle user index\n",
    "        if userID in user2index:\n",
    "            user_idx = user2index[userID]\n",
    "            beta_u = beta_user_values[user_idx].item()\n",
    "        else:\n",
    "            beta_u = 0.0  # Default value for unseen users\n",
    "\n",
    "        # Handle item index\n",
    "        if itemID in item2index:\n",
    "            item_idx = item2index[itemID]\n",
    "            beta_i = beta_item_values[item_idx].item()\n",
    "        else:\n",
    "            beta_i = 0.0  # Default value for unseen items\n",
    "\n",
    "        # Compute the predicted rating\n",
    "        pred_rating = alpha_value + beta_u + beta_i\n",
    "\n",
    "        # Optional: Clip the predicted rating to the valid range (e.g., 1 to 5)\n",
    "        # pred_rating = max(1.0, min(5.0, pred_rating))\n",
    "\n",
    "        # Write the prediction\n",
    "        predictions.write(f\"{userID},{itemID},{pred_rating}\\n\")\n",
    "\n",
    "# Close the predictions file\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "839261ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_hw3.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3000bdde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
