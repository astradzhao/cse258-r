{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import torch\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVDpp, accuracy, KNNBaseline\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N\n",
    "\n",
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r\n",
    "\n",
    "allRatings = []\n",
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)\n",
    "\n",
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "bookUsers = defaultdict(set)\n",
    "userBooks = defaultdict(set)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "    bookUsers[b].add(u)\n",
    "    userBooks[u].add(b)\n",
    "\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from surprise import Dataset, Reader, SVDpp, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames from the training and validation data\n",
    "df_train = pd.DataFrame(ratingsTrain, columns=['userID', 'itemID', 'rating'])\n",
    "df_valid = pd.DataFrame(ratingsValid, columns=['userID', 'itemID', 'rating'])\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Prepare the training data\n",
    "train_data = Dataset.load_from_df(df_train[['userID', 'itemID', 'rating']], reader)\n",
    "trainset = train_data.build_full_trainset()\n",
    "\n",
    "# Prepare the testset (validation data)\n",
    "testset = list(zip(df_valid['userID'], df_valid['itemID'], df_valid['rating']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_factors': [1],\n",
    "    'n_epochs': [19],\n",
    "    'lr_bu': [0.01],\n",
    "    'lr_bi': [0.005],\n",
    "    'lr_pu': [0.001],\n",
    "    'lr_qi': [0.005],\n",
    "    'reg_bu': [0.15],\n",
    "    'reg_bi': [0.08],\n",
    "    'reg_pu': [0.1],\n",
    "    'reg_qi': [0.1],\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'n_factors': 1, 'n_epochs': 19, 'lr_bu': 0.01, 'lr_bi': 0.005, 'lr_pu': 0.001, 'lr_qi': 0.005, 'reg_bu': 0.15, 'reg_bi': 0.08, 'reg_pu': 0.1, 'reg_qi': 0.1, 'random_state': 420} => RMSE: 1.1879\n",
      "\n",
      "Best RMSE: 1.1879 with parameters: {'n_factors': 1, 'n_epochs': 19, 'lr_bu': 0.01, 'lr_bi': 0.005, 'lr_pu': 0.001, 'lr_qi': 0.005, 'reg_bu': 0.15, 'reg_bi': 0.08, 'reg_pu': 0.1, 'reg_qi': 0.1, 'random_state': 420}\n"
     ]
    }
   ],
   "source": [
    "# Generate all combinations of parameters\n",
    "param_names = list(param_grid.keys())\n",
    "param_values = list(param_grid.values())\n",
    "param_combinations = [dict(zip(param_names, v)) for v in product(*param_values)]\n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for params in param_combinations:\n",
    "    algo_params = {k: v for k, v in params.items() if v is not None}\n",
    "    algo_params['random_state'] = 420\n",
    "    algo = SVD(**algo_params)\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "    print(f\"Parameters: {algo_params} => RMSE: {rmse:.4f}\")\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_params = algo_params\n",
    "\n",
    "print(f\"\\nBest RMSE: {best_rmse:.4f} with parameters: {best_params}\")\n",
    "\n",
    "#Parameters: {'n_factors': 1, 'n_epochs': 20, 'lr_bu': 0.005, 'lr_bi': 0.005, 'lr_pu': 0.005, 'lr_qi': 0.001, 'reg_bu': 0.01, 'reg_bi': 0.05, 'reg_pu': 0.05, 'reg_qi': 0.01, 'random_state': 100} => RMSE: 1.1920\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pp_params = {'n_factors': 3, 'n_epochs': 20, 'lr_bu': 0.01, 'lr_bi': 0.006, 'lr_pu': 0.001, 'lr_qi': 0.005, 'reg_bu': 0.15, 'reg_bi': 0.1, 'reg_pu': 0.1, 'reg_qi': 0.1}\n",
    "best_svd_params = {'n_factors': 1, 'n_epochs': 19, 'lr_bu': 0.01, 'lr_bi': 0.005, 'lr_pu': 0.001, 'lr_qi': 0.005, 'reg_bu': 0.15, 'reg_bi': 0.08, 'reg_pu': 0.1, 'reg_qi': 0.1, 'random_state': 139}\n",
    "#algo = SVDpp(**best_params)\n",
    "algo = SVD(**best_svd_params)\n",
    "# Train the algorithm\n",
    "algo.fit(trainset)\n",
    "\n",
    "with open(\"pairs_Rating.csv\", 'r') as pairs_file, open(\"predictions_Rating.csv\", 'w') as predictions:\n",
    "    for line in pairs_file:\n",
    "        if line.startswith(\"userID\"):\n",
    "            predictions.write(line)\n",
    "            continue\n",
    "        userID, itemID = line.strip().split(',')\n",
    "\n",
    "        # Predict the rating\n",
    "        pred = algo.predict(userID, itemID)\n",
    "        predRating = pred.est\n",
    "\n",
    "        # Write the prediction\n",
    "        predictions.write(f\"{userID},{itemID},{predRating}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'n_factors': 0, 'n_epochs': 0, 'lr_all': 0.007394651229831707, 'reg_all': 0.07947268945576047} => RMSE: 1.3142\n"
     ]
    }
   ],
   "source": [
    "best_params1 = {'n_factors': 0, 'n_epochs': 0, 'lr_all': 0.007394651229831707,  'reg_all': 0.07947268945576047}\n",
    "algo = SVD(**best_params1)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "rmse = accuracy.rmse(predictions, verbose=False)\n",
    "print(f\"Parameters: {best_params1} => RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1882\n",
      "Ensemble Validation RMSE: 1.188164237663758\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVDpp, KNNBaseline\n",
    "\n",
    "# Train SVD model\n",
    "algo1 = SVDpp(**best_pp_params)\n",
    "algo1.fit(trainset)\n",
    "\n",
    "# Train KNNBaseline model\n",
    "algo2 = SVD(**best_svd_params)\n",
    "algo2.fit(trainset)\n",
    "\n",
    "# Get predictions\n",
    "predictions1 = algo1.test(testset)\n",
    "predictions2 = algo2.test(testset)\n",
    "\n",
    "# Combine predictions\n",
    "def combine_predictions(preds1, preds2):\n",
    "    combined_preds = []\n",
    "    for p1, p2 in zip(preds1, preds2):\n",
    "        est = p1.est * 0.8 + p2.est * 0.2\n",
    "        combined_preds.append(p1._replace(est=est))\n",
    "    return combined_preds\n",
    "\n",
    "combined_predictions = combine_predictions(predictions1, predictions2)\n",
    "rmse = accuracy.rmse(combined_predictions)\n",
    "print(f\"Ensemble Validation RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pairs_Rating.csv\", 'r') as pairs_file, open(\"predictions_Rating.csv\", 'w') as predictions:\n",
    "    for line in pairs_file:\n",
    "        if line.startswith(\"userID\"):\n",
    "            predictions.write(line)\n",
    "            continue\n",
    "        userID, itemID = line.strip().split(',')\n",
    "        # Predict the rating\n",
    "        pred1 = algo1.predict(userID, itemID)\n",
    "        pred2 = algo2.predict(userID, itemID)\n",
    "        predRating = pred1.est * 0.8 + pred2.est * 0.2\n",
    "\n",
    "        # Write the prediction\n",
    "        predictions.write(f\"{userID},{itemID},{predRating}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:40<00:00,  1.23trial/s, best loss: 1.189038056796004] \n",
      "Best parameters: {'lr_all': 0.007394651229831707, 'n_epochs': 0, 'n_factors': 0, 'reg_all': 0.07947268945576047}\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "\n",
    "def objective(params):\n",
    "    algo = SVD(random_state=420, **params)\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "    return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "param_space = {\n",
    "    'n_factors': hp.choice('n_factors', [1, 10, 20]),\n",
    "    'n_epochs': hp.choice('n_epochs', [20]),\n",
    "    'lr_all': hp.loguniform('lr_all', -5, -2),\n",
    "    'reg_all': hp.loguniform('reg_all', -5, -2),\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=param_space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
    "print(f\"Best parameters: {best}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
