{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N\n",
    "\n",
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r\n",
    "\n",
    "allRatings = []\n",
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)\n",
    "\n",
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "bookUsers = defaultdict(set)\n",
    "userBooks = defaultdict(set)\n",
    "\n",
    "userInteractionCounts = defaultdict(int)\n",
    "bookInteractionCounts = defaultdict(int)\n",
    "\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "    bookUsers[b].add(u)\n",
    "    userBooks[u].add(b)\n",
    "    userInteractionCounts[u] += 1\n",
    "    bookInteractionCounts[b] += 1\n",
    "    \n",
    "\n",
    "medianUserInteractions = np.median(list(userInteractionCounts.values()))\n",
    "medianBookInteractions = np.median(list(bookInteractionCounts.values()))\n",
    "\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalRead/2: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_valid_samples = []\n",
    "\n",
    "for user, book, _ in ratingsValid:\n",
    "     negative_books = set()\n",
    "     while len(negative_books) < 1:\n",
    "        negative_book = random.choice(list(bookCount.keys()))\n",
    "        if all(b != negative_book for b, _ in ratingsPerUser[user]) and negative_book not in negative_books:\n",
    "            negative_books.add(negative_book)\n",
    "            negative_valid_samples.append((user, negative_book, 0))  # 0 for negative sample\n",
    "\n",
    "validation_with_negatives = [(u, b, 1) for u, b, _ in ratingsValid] + negative_valid_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccardSim(book1, book2):\n",
    "    users1 = bookUsers.get(book1, set())\n",
    "    users2 = bookUsers.get(book2, set())\n",
    "    if not users1 or not users2:\n",
    "        return 0\n",
    "    intersection = len(users1.intersection(users2))\n",
    "    union = len(users1.union(users2))\n",
    "    return intersection / union\n",
    "\n",
    "def maxJaccardSimilarity(user, book):\n",
    "    return max([jaccardSim(book, b_read) for b_read in userBooks[user] if b_read != book], default=0)\n",
    "\n",
    "def avgJaccardSimilarity(user, book):\n",
    "    ans = [jaccardSim(book, b_read) for b_read in userBooks[user] if b_read != book]\n",
    "    return np.mean(ans) if ans else 0\n",
    "\n",
    "def cosineSim(book1, book2):\n",
    "    users1 = bookUsers.get(book1, set())\n",
    "    users2 = bookUsers.get(book2, set())\n",
    "    if not users1 or not users2:\n",
    "        return 0\n",
    "    intersection = len(users1.intersection(users2))\n",
    "    magnitude1 = math.sqrt(len(users1))\n",
    "    magnitude2 = math.sqrt(len(users2))\n",
    "    return intersection / (magnitude1 * magnitude2)\n",
    "\n",
    "\n",
    "def maxCosineSimilarity(user, book):\n",
    "    return max([cosineSim(book, b_read) for b_read in userBooks[user]], default=0)\n",
    "\n",
    "def avgCosineSimilarity(user, book):\n",
    "    ans = [cosineSim(book, b_read) for b_read in userBooks[user] if b_read != book]\n",
    "    return np.mean(ans) if ans else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "trainRecords = []\n",
    "\n",
    "for u, b, _ in ratingsTrain:\n",
    "    numBookInteractions = bookInteractionCounts.get(b, medianBookInteractions)\n",
    "    numUserInteractions = userInteractionCounts.get(u, medianUserInteractions)\n",
    "    maxJaccardSim = maxJaccardSimilarity(u, b)\n",
    "    maxCosineSim = maxCosineSimilarity(u, b)\n",
    "    avgJaccardSim = avgJaccardSimilarity(u, b)\n",
    "    avgCosineSim = avgCosineSimilarity(u, b)\n",
    "    isPopular = 1 if b in mostPopular else 0\n",
    "    \n",
    "    trainRecords.append({\n",
    "        'user': u,\n",
    "        'book': b,\n",
    "        'book_popularity': numBookInteractions,\n",
    "        'user_interactions': numUserInteractions,\n",
    "        'is_popular': isPopular,\n",
    "        'max_jaccard_sim': maxJaccardSim,\n",
    "        'max_cosine_sim': maxCosineSim,\n",
    "        'avg_jaccard_sim': avgJaccardSim,\n",
    "        'avg_cosine_sim': avgCosineSim,\n",
    "        'label': 1\n",
    "    })\n",
    "    \n",
    "    while True:\n",
    "        negBook = random.choice(list(bookCount.keys()))\n",
    "        if negBook not in userBooks[u]:\n",
    "            numBookInteractions = bookInteractionCounts.get(negBook, medianBookInteractions)\n",
    "            numUserInteractions = userInteractionCounts.get(u, medianUserInteractions)\n",
    "            maxJaccardSim = maxJaccardSimilarity(u, negBook)\n",
    "            maxCosineSim = maxCosineSimilarity(u, negBook)\n",
    "            avgJaccardSim = avgJaccardSimilarity(u, negBook)\n",
    "            avgCosineSim = avgCosineSimilarity(u, negBook)\n",
    "            isPopular = 1 if b in mostPopular else 0\n",
    "\n",
    "            trainRecords.append({\n",
    "                'user': u,\n",
    "                'book': negBook,\n",
    "                'book_popularity': numBookInteractions,\n",
    "                'user_interactions': numUserInteractions,\n",
    "                'is_popular': isPopular,\n",
    "                'max_jaccard_sim': maxJaccardSim,\n",
    "                'max_cosine_sim': maxCosineSim,\n",
    "                'avg_jaccard_sim': avgJaccardSim,\n",
    "                'avg_cosine_sim': avgCosineSim,\n",
    "                'label': 0\n",
    "            })\n",
    "            break\n",
    "\n",
    "trainDf = pd.DataFrame(trainRecords)\n",
    "\n",
    "validRecords = []\n",
    "\n",
    "for u, b, label in validation_with_negatives:\n",
    "    numBookInteractions = bookInteractionCounts.get(b, medianBookInteractions)\n",
    "    numUserInteractions = userInteractionCounts.get(u, medianUserInteractions)\n",
    "    isPopular = 1 if b in mostPopular else 0\n",
    "    maxJaccardSim = maxJaccardSimilarity(u, b)\n",
    "    maxCosineSim = maxCosineSimilarity(u, b)\n",
    "    avgJaccardSim = avgJaccardSimilarity(u, b)\n",
    "    avgCosineSim = avgCosineSimilarity(u, b)\n",
    "\n",
    "    validRecords.append({\n",
    "        'user': u,\n",
    "        'book': b,\n",
    "        'book_popularity': numBookInteractions,\n",
    "        'user_interactions': numUserInteractions,\n",
    "        'is_popular': isPopular,\n",
    "        'max_jaccard_sim': maxJaccardSim,\n",
    "        'max_cosine_sim': maxCosineSim,\n",
    "        'avg_jaccard_sim': avgJaccardSim,\n",
    "        'avg_cosine_sim': avgCosineSim,\n",
    "        'label': label\n",
    "    })\n",
    "\n",
    "validDf = pd.DataFrame(validRecords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values and standardize features\n",
    "featureCols = ['book_popularity', 'user_interactions', 'max_jaccard_sim', 'max_cosine_sim', 'avg_jaccard_sim', 'avg_cosine_sim']\n",
    "trainDf[featureCols] = trainDf[featureCols].fillna(0)\n",
    "validDf[featureCols] = validDf[featureCols].fillna(0)\n",
    "\n",
    "trainDf[['book_popularity_scaled', 'user_interactions_scaled']] = scaler.fit_transform(trainDf[['book_popularity', 'user_interactions']])\n",
    "validDf[['book_popularity_scaled', 'user_interactions_scaled']] = scaler.transform(validDf[['book_popularity', 'user_interactions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureCols = ['book_popularity_scaled', 'user_interactions_scaled', 'is_popular', 'max_jaccard_sim', 'avg_cosine_sim']\n",
    "trainFeatures = np.array(trainDf[featureCols])\n",
    "validFeatures = np.array(validDf[featureCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7556\n",
      "Validation AUC: 0.8226\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77     10000\n",
      "           1       0.78      0.71      0.74     10000\n",
      "\n",
      "    accuracy                           0.76     20000\n",
      "   macro avg       0.76      0.76      0.76     20000\n",
      "weighted avg       0.76      0.76      0.76     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=10000, C = 0.005)\n",
    "model.fit(trainFeatures, trainDf['label'])\n",
    "\n",
    "validProbs = model.predict_proba(validFeatures)[:, 1]\n",
    "n_test = len(validProbs)\n",
    "\n",
    "n_positive = n_test // 2\n",
    "sorted_indices = np.argsort(-validProbs)\n",
    "\n",
    "validPreds = np.zeros(n_test, dtype=int)\n",
    "validPreds[sorted_indices[:n_positive]] = 1\n",
    "\n",
    "validPreds = (validProbs >= 0.35).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(validDf['label'], validPreds)\n",
    "auc = roc_auc_score(validDf['label'], validProbs)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Validation AUC: {auc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(validDf['label'], validPreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40851065, 0.99743297, 0.32158174, 0.70294376, 0.84803255,\n",
       "       0.54243706, 0.63005725, 0.88574091, 0.99146794, 0.36917487])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validProbs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44711378, 0.9983031 , 0.31994058, 0.70821143, 0.8546782 ,\n",
       "       0.54027241, 0.6531626 , 0.89921993, 0.99289062, 0.34979513,\n",
       "       0.99665277, 0.25373251, 0.99998982, 0.90485009, 0.66688095,\n",
       "       0.45956429, 0.4601712 , 0.90869636, 0.27798971, 0.98132337,\n",
       "       0.36442192, 0.70186892, 0.25306995, 0.47631094, 0.91252158,\n",
       "       0.28119819, 0.99704291, 0.99647736, 0.99971581, 0.35990137,\n",
       "       0.24717274, 0.98871317, 0.35699037, 0.24612964, 0.34387864,\n",
       "       0.21602708, 0.42118277, 0.21873706, 0.82156536, 0.78262547,\n",
       "       0.7936214 , 0.99169941, 0.38185029, 0.8188856 , 0.99974792,\n",
       "       0.96538959, 0.88107921, 0.68963043, 0.43442545, 0.37923922,\n",
       "       0.41334405, 0.27130194, 0.99962363, 0.39061746, 0.67356401,\n",
       "       0.22982065, 0.30574848, 0.90013181, 0.53200398, 0.9999986 ,\n",
       "       0.22701326, 0.48456844, 0.26228966, 0.46058446, 0.5511289 ,\n",
       "       0.65723254, 0.30978371, 0.46992026, 0.99994631, 0.98116958,\n",
       "       0.91232414, 0.73598245, 0.70925671, 0.24670752, 0.26961788,\n",
       "       0.47398312, 0.72959443, 0.87177246, 0.93356091, 0.93721078,\n",
       "       0.4389019 , 0.93183612, 0.38608525, 0.9034137 , 0.75661984,\n",
       "       0.99993252, 0.22982065, 0.21602708, 0.46353955, 0.26538353,\n",
       "       0.68464643, 0.24129241, 0.24972393, 0.22423017, 0.99999522,\n",
       "       0.24129241, 0.26817856, 0.99984225, 0.92575761, 0.30427537])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validProbs[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00155755, 0.011709  , 0.001266  , ..., 0.00099842, 0.00072374,\n",
       "       0.00074837])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validProbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs = []\n",
    "\n",
    "with open(\"pairs_Read.csv\", 'r') as f:\n",
    "    for l in f:\n",
    "        if l.startswith(\"userID\"):\n",
    "            continue\n",
    "        u, b = l.strip().split(',')\n",
    "        test_pairs.append((u, b))\n",
    "\n",
    "test_records = []\n",
    "\n",
    "for u, b in test_pairs:\n",
    "    # Book popularity from training data\n",
    "    numBookInteractions = bookInteractionCounts.get(b, medianBookInteractions)\n",
    "    numUserInteractions = userInteractionCounts.get(u, medianUserInteractions)\n",
    "    isPopular = 1 if b in mostPopular else 0\n",
    "\n",
    "    maxJaccardSim = maxJaccardSimilarity(u, b)\n",
    "    maxCosineSim = maxCosineSimilarity(u, b)\n",
    "    avgJaccardSim = avgJaccardSimilarity(u, b)\n",
    "    avgCosineSim = avgCosineSimilarity(u, b)\n",
    "    \n",
    "    test_records.append({\n",
    "        'user': u,\n",
    "        'book': b,\n",
    "        'book_popularity': numBookInteractions,\n",
    "        'user_interactions': numUserInteractions,\n",
    "        'is_popular': isPopular,\n",
    "        'max_jaccard_sim': maxJaccardSim,\n",
    "        'max_cosine_sim': maxCosineSim,\n",
    "        'avg_jaccard_sim': avgJaccardSim,\n",
    "        'avg_cosine_sim': avgCosineSim,\n",
    "    })\n",
    "\n",
    "test_df = pd.DataFrame(test_records)\n",
    "\n",
    "test_df[['book_popularity_scaled', 'user_interactions_scaled']] = scaler.transform(test_df[['book_popularity', 'user_interactions']])\n",
    "feature_cols = ['book_popularity_scaled', 'user_interactions_scaled', 'is_popular', 'max_jaccard_sim', 'avg_jaccard_sim']\n",
    "test_df[feature_cols] = test_df[feature_cols].fillna(0)\n",
    "test_features = test_df[feature_cols]\n",
    "\n",
    "test_probs = model.predict_proba(test_features)[:, 1]\n",
    "test_preds = (test_probs >= 0.35).astype(int)\n",
    "# n_test = len(test_probs)\n",
    "\n",
    "# n_positive = n_test // 2\n",
    "# sorted_indices = np.argsort(-test_probs)\n",
    "\n",
    "# test_preds = np.zeros(n_test, dtype=int)\n",
    "# test_preds[sorted_indices[:n_positive]] = 1\n",
    "\n",
    "with open(\"predictions_Read.csv\", 'w') as predictions:\n",
    "    predictions.write(\"userID,bookID,prediction\\n\")\n",
    "    \n",
    "    for idx, (u, b) in enumerate(test_pairs):\n",
    "        prediction = test_preds[idx]\n",
    "        predictions.write(f\"{u},{b},{prediction}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
